"""
API-–≤–µ—Ä—Å–∏—è CSV Analysis Agent –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–µ—Ä–≤–∏—Å–∞–º–∏
Julius.ai style - –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫—Ä–∞—Å–∏–≤—ã–º –≤—ã–≤–æ–¥–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Å base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
"""

import os
import io
import json
import traceback
import gc
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import contextlib
import base64
from datetime import datetime

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from openai import OpenAI


# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
AVAILABLE_MODELS = {
    "claude-sonnet-4.5": {
        "id": "anthropic/claude-sonnet-4.5",
        "name": "Claude Sonnet 4.5",
        "provider": "Anthropic",
        "description": "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–ª–æ–∂–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞",
        "context_length": 200000,
        "recommended": True
    },
    "gpt-4o": {
        "id": "openai/gpt-4o",
        "name": "GPT-4o",
        "provider": "OpenAI",
        "description": "–ú–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å –æ—Ç OpenAI —Å –æ—Ç–ª–∏—á–Ω—ã–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö",
        "context_length": 128000,
        "recommended": True
    },
    "deepseek-chat": {
        "id": "deepseek/deepseek-chat",
        "name": "DeepSeek Chat",
        "provider": "DeepSeek",
        "description": "–ë—ã—Å—Ç—Ä–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö",
        "context_length": 64000,
        "recommended": False
    },
    "qwen-2.5-72b": {
        "id": "qwen/qwen-2.5-72b-instruct",
        "name": "Qwen 2.5 72B",
        "provider": "Alibaba",
        "description": "–û—Ç–∫—Ä—ã—Ç–∞—è –º–æ–¥–µ–ª—å —Å –æ—Ç–ª–∏—á–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º",
        "context_length": 32000,
        "recommended": False
    },
    "llama-3.3-70b": {
        "id": "meta-llama/llama-3.3-70b-instruct",
        "name": "Llama 3.3 70B",
        "provider": "Meta",
        "description": "–û—Ç–∫—Ä—ã—Ç–∞—è –º–æ–¥–µ–ª—å –æ—Ç Meta —Å —Ö–æ—Ä–æ—à–∏–º–∏ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–º–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è–º–∏",
        "context_length": 128000,
        "recommended": False
    }
}

# –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
DEFAULT_MODEL = "claude-sonnet-4.5"


class CSVAnalysisAgentAPI:
    """
    API-–≤–µ—Ä—Å–∏—è –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ CSV —Ñ–∞–π–ª–æ–≤ (Julius.ai style)
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ API
    """

    def __init__(self, api_key: str, model: str = DEFAULT_MODEL):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞

        Args:
            api_key: API –∫–ª—é—á –¥–ª—è OpenRouter
            model: –ö–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "claude-sonnet-4.5", "gpt-4o")
                   –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Claude Sonnet 4.5
        """
        self.api_key = api_key

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenRouter
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key
        )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏
        if model not in AVAILABLE_MODELS:
            raise ValueError(
                f"–ú–æ–¥–µ–ª—å '{model}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. "
                f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {', '.join(AVAILABLE_MODELS.keys())}"
            )

        self.model_key = model  # –ö–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è (–∫–ª—é—á)
        self.model = AVAILABLE_MODELS[model]["id"]  # –ü–æ–ª–Ω—ã–π ID –¥–ª—è API
        self.model_info = AVAILABLE_MODELS[model]  # –ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏

        self.current_df = None
        self.original_df = None  # –•—Ä–∞–Ω–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        self.dataframes = {}  # –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö DataFrame: {filename: df}
        self.max_retries = 3

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –¥–∞–Ω–Ω—ã—Ö
        self.data_metadata = {
            "has_unnamed_columns": False,
            "first_row_is_header": False,
            "columns_cleaned": False,
            "rows_removed": 0,
            "cols_removed": 0
        }

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        sns.set_style("whitegrid")
        plt.rcParams['figure.figsize'] = (10, 6)
        plt.rcParams['figure.dpi'] = 100

    def _is_first_row_header(self, df: pd.DataFrame) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º

        –ö—Ä–∏—Ç–µ—Ä–∏–∏:
        1. –¢–µ–∫—É—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Ç–∏–ø–∞ "Unnamed: 0", "Unnamed: 1"...
        2. –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è)
        3. –í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Å–ª–æ–≤—ã–µ/—Å–º–µ—à–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–¥–∞–Ω–Ω—ã–µ)
        """
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –ú–Ω–æ–≥–æ Unnamed –∫–æ–ª–æ–Ω–æ–∫?
        unnamed_count = sum(1 for col in df.columns if 'Unnamed' in str(col))
        if unnamed_count < len(df.columns) * 0.3:  # –ú–µ–Ω—å—à–µ 30% unnamed
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - —Ç–µ–∫—Å—Ç?
        if len(df) < 2:
            return False

        first_row = df.iloc[0]
        second_row = df.iloc[1]

        # –°—á–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ
        text_count_row1 = sum(1 for val in first_row if isinstance(val, str) and not str(val).replace('.', '').replace('-', '').isdigit())

        # –°—á–∏—Ç–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–æ –≤—Ç–æ—Ä–æ–π —Å—Ç—Ä–æ–∫–µ
        numeric_count_row2 = sum(1 for val in second_row if pd.notna(val) and (isinstance(val, (int, float)) or str(val).replace('.', '').replace('-', '').isdigit()))

        # –ï—Å–ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —Ç–µ–∫—Å—Ç, –∞ –≤—Ç–æ—Ä–∞—è - —á–∏—Å–ª–∞
        return text_count_row1 > len(first_row) * 0.5 and numeric_count_row2 > len(second_row) * 0.3

    def smart_load_csv(self, file_bytes: bytes, filename: str = "data.csv") -> Dict[str, Any]:
        """
        –£–º–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ CSV —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        –†–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ Julius.ai - —Å–Ω–∞—á–∞–ª–∞ –ø–æ–Ω–∏–º–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –ø–æ—Ç–æ–º –æ—á–∏—â–∞–µ—Ç

        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∑–∞–≥—Ä—É–∑–∫–µ –∏ –æ—á–∏—Å—Ç–∫–µ
        """
        load_info = {
            "filename": filename,
            "steps": [],
            "warnings": [],
            "original_shape": None,
            "final_shape": None,
            "success": True
        }

        try:
            # –®–ê–ì 1: –ó–∞–≥—Ä—É–∂–∞–µ–º "–∫–∞–∫ –µ—Å—Ç—å"
            df_raw = pd.read_csv(io.BytesIO(file_bytes), sep=None, engine='python')
            self.original_df = df_raw.copy()
            load_info["original_shape"] = df_raw.shape
            load_info["steps"].append(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {df_raw.shape[0]} —Å—Ç—Ä–æ–∫ √ó {df_raw.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")

            # –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä—è–µ–º "Unnamed" –∫–æ–ª–æ–Ω–∫–∏
            unnamed_cols = [col for col in df_raw.columns if 'Unnamed' in str(col)]
            if unnamed_cols:
                self.data_metadata["has_unnamed_columns"] = True
                load_info["warnings"].append(
                    f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(unnamed_cols)} –∫–æ–ª–æ–Ω–æ–∫ —Ç–∏–ø–∞ 'Unnamed'. "
                    f"–í–æ–∑–º–æ–∂–Ω–æ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏."
                )
                load_info["steps"].append(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(unnamed_cols)} –±–µ–∑—ã–º—è–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")

            # –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É - –º–æ–∂–µ—Ç —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏?
            if self._is_first_row_header(df_raw):
                self.data_metadata["first_row_is_header"] = True
                load_info["steps"].append("üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ: –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö")

                # –î–µ–ª–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
                new_columns = df_raw.iloc[0].tolist()
                df_raw.columns = new_columns
                df_raw = df_raw.iloc[1:].reset_index(drop=True)

                load_info["steps"].append("‚úÖ –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∏")

            # –®–ê–ì 4: –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –æ—Ç –ø—Ä–æ–±–µ–ª–æ–≤
            original_cols = list(df_raw.columns)
            df_raw.columns = df_raw.columns.astype(str).str.strip()
            cleaned_cols = list(df_raw.columns)

            if original_cols != cleaned_cols:
                self.data_metadata["columns_cleaned"] = True
                load_info["steps"].append("üßπ –û—á–∏—â–µ–Ω—ã –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤")

            # –®–ê–ì 5: –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            rows_before = len(df_raw)
            df_raw = df_raw.dropna(how='all')
            rows_after = len(df_raw)
            rows_removed = rows_before - rows_after

            if rows_removed > 0:
                self.data_metadata["rows_removed"] = rows_removed
                load_info["steps"].append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {rows_removed} –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫")

            # –®–ê–ì 6: –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            cols_before = len(df_raw.columns)
            df_raw = df_raw.dropna(axis=1, how='all')
            cols_after = len(df_raw.columns)
            cols_removed = cols_before - cols_after

            if cols_removed > 0:
                self.data_metadata["cols_removed"] = cols_removed
                load_info["steps"].append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {cols_removed} –ø—É—Å—Ç—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.current_df = df_raw.reset_index(drop=True)
            clean_name = Path(filename).stem
            self.dataframes[clean_name] = self.current_df

            load_info["final_shape"] = self.current_df.shape
            load_info["steps"].append(
                f"‚úÖ –ò—Ç–æ–≥–æ: {self.current_df.shape[0]} —Å—Ç—Ä–æ–∫ √ó {self.current_df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫"
            )

            return load_info

        except Exception as e:
            load_info["success"] = False
            load_info["error"] = str(e)
            raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ CSV —Ñ–∞–π–ª–∞ '{filename}': {str(e)}")

    def load_csv_from_bytes(self, file_bytes: bytes, filename: str = "data.csv") -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å CSV –∏–∑ –±–∞–π—Ç–æ–≤ (—Å —É–º–Ω–æ–π –æ—á–∏—Å—Ç–∫–æ–π)

        Args:
            file_bytes: –ë–∞–π—Ç—ã CSV —Ñ–∞–π–ª–∞
            filename: –ò–º—è —Ñ–∞–π–ª–∞

        Returns:
            DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        """
        self.smart_load_csv(file_bytes, filename)
        return self.current_df

    def load_multiple_csv(self, files_data: List[Tuple[bytes, str]]) -> Dict[str, pd.DataFrame]:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ CSV —Ñ–∞–π–ª–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ

        Args:
            files_data: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (file_bytes, filename)

        Returns:
            –°–ª–æ–≤–∞—Ä—å {filename: DataFrame}
        """
        loaded = {}
        for file_bytes, filename in files_data:
            self.smart_load_csv(file_bytes, filename)
            clean_name = Path(filename).stem
            loaded[clean_name] = self.dataframes[clean_name]

        # –ü–µ—Ä–≤—ã–π —Ñ–∞–π–ª - –æ—Å–Ω–æ–≤–Ω–æ–π
        if files_data:
            self.current_df = loaded[Path(files_data[0][1]).stem]

        return loaded

    def load_csv_from_file(self, file_path: str) -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å CSV –∏–∑ –ø—É—Ç–∏

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É

        Returns:
            DataFrame
        """
        with open(file_path, 'rb') as f:
            file_bytes = f.read()
        return self.load_csv_from_bytes(file_bytes, os.path.basename(file_path))

    def analyze_csv_schema(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ —Å—Ö–µ–º—ã CSV —Ñ–∞–π–ª–∞

        Args:
            df: DataFrame –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ö–µ–º–µ
        """
        schema = {
            "columns": list(df.columns),
            "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
            "shape": {"rows": int(df.shape[0]), "columns": int(df.shape[1])},
            "missing_values": {col: int(count) for col, count in df.isnull().sum().items()},
            "sample_data": df.head(5).to_dict(orient='records'),
            "summary_stats": {},
            "metadata": self.data_metadata
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            stats_df = df[numeric_cols].describe()
            schema["summary_stats"] = {
                col: {stat: float(val) for stat, val in stats_df[col].items()}
                for col in numeric_cols
            }

        return schema

    def execute_python_code(self, code: str, df: pd.DataFrame) -> Tuple[bool, Any, str, List[str]]:
        """
        –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Python –∫–æ–¥–∞ —Å –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ base64

        Args:
            code: Python –∫–æ–¥ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            df: DataFrame –¥–ª—è —Ä–∞–±–æ—Ç—ã (–æ—Å–Ω–æ–≤–Ω–æ–π)

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—É—Å–ø–µ—Ö, —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –≤—ã–≤–æ–¥/–æ—à–∏–±–∫–∞, —Å–ø–∏—Å–æ–∫ base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)
        """
        local_vars = {
            'df': df.copy(),
            'pd': pd,
            'np': np,
            'plt': plt,
            'sns': sns,
            'result': None
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ DataFrame'—ã
        for name, dataframe in self.dataframes.items():
            local_vars[name] = dataframe.copy()

        stdout_capture = io.StringIO()
        stderr_capture = io.StringIO()
        plot_base64_list = []

        try:
            with contextlib.redirect_stdout(stdout_capture), \
                 contextlib.redirect_stderr(stderr_capture):

                # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–¥
                exec(code, local_vars)

                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                result = local_vars.get('result', None)
                output = stdout_capture.getvalue()

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON-serializable —Ñ–æ—Ä–º–∞—Ç
                if isinstance(result, (np.integer, np.floating)):
                    result = float(result)
                elif isinstance(result, np.ndarray):
                    result = result.tolist()
                elif isinstance(result, pd.DataFrame) or isinstance(result, pd.Series):
                    # –ï—Å–ª–∏ AI –≤–µ—Ä–Ω—É–ª DataFrame –≤–º–µ—Å—Ç–æ Markdown - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
                    result = str(result)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –≤ base64
                if plt.get_fignums():
                    for fig_num in plt.get_fignums():
                        fig = plt.figure(fig_num)

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±—É—Ñ–µ—Ä
                        buffer = io.BytesIO()
                        fig.savefig(buffer, format='png', bbox_inches='tight', dpi=150)
                        buffer.seek(0)

                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
                        img_base64 = base64.b64encode(buffer.read()).decode('utf-8')
                        plot_base64_list.append(f"data:image/png;base64,{img_base64}")

                        buffer.close()

                    plt.close('all')

                return True, result, output, plot_base64_list

        except Exception as e:
            error_msg = f"{type(e).__name__}: {str(e)}\n{traceback.format_exc()}"
            return False, None, error_msg, []
        finally:
            # –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ matplotlib
            plt.close('all')
            plt.clf()
            # –û—á–∏—â–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
            local_vars.clear()

    def generate_code_with_retry(self, user_query: str, schema: Dict,
                                 chat_history: List[Dict] = None,
                                 previous_error: Optional[str] = None) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Python –∫–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é AI (Julius.ai style - –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω—ã–π –ø–æ–¥—Ö–æ–¥)

        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            schema: –°—Ö–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö CSV
            chat_history: –ò—Å—Ç–æ—Ä–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            previous_error: –ü—Ä–µ–¥—ã–¥—É—â–∞—è –æ—à–∏–±–∫–∞ (–¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏)

        Returns:
            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Python –∫–æ–¥
        """
        system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö, —Ä–∞–±–æ—Ç–∞—é—â–∏–π –∫–∞–∫ Julius.ai.

üéØ –¢–í–û–Ø –ó–ê–î–ê–ß–ê: –ü–∏—Å–∞—Ç—å –∫–æ–¥ –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç –ü–û–≠–¢–ê–ü–ù–û –∏ –õ–û–ì–ò–†–£–ï–¢ –∫–∞–∂–¥—ã–π —à–∞–≥.

üìã –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê –ö–û–î–ê:

```python
# === –®–ê–ì 1: –ü–û–ù–ò–ú–ê–ù–ò–ï –î–ê–ù–ù–´–• ===
print("üîç –®–ê–ì 1: –ò–∑—É—á–∞—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö...")
print(f"–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
print(f"–ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")

# === –®–ê–ì 2: –ü–†–û–í–ï–†–ö–ê –ò –û–ß–ò–°–¢–ö–ê ===
print("\\nüßπ –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä—è—é –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö...")

# –ò—â–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–≥–∏–±–∫–∏–π –ø–æ–∏—Å–∫)
def find_column(df, keywords):
    for col in df.columns:
        col_lower = str(col).lower()
        if any(keyword.lower() in col_lower for keyword in keywords):
            return col
    return None

year_col = find_column(df, ['year', '–≥–æ–¥', 'date'])
amount_col = find_column(df, ['amount', '—Å—É–º–º–∞', 'total', 'value'])

if not year_col or not amount_col:
    result = f"‚ùå –û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {list(df.columns)}"
else:
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏: {year_col}, {amount_col}")

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
    df[year_col] = pd.to_numeric(df[year_col], errors='coerce')
    df[amount_col] = pd.to_numeric(df[amount_col], errors='coerce')

    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    df_clean = df.dropna(subset=[year_col, amount_col])
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã: {len(df_clean)} –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫")

    # === –®–ê–ì 3: –ê–ù–ê–õ–ò–ó ===
    print("\\nüìä –®–ê–ì 3: –í—ã–ø–æ–ª–Ω—è—é –∞–Ω–∞–ª–∏–∑...")

    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è
    result_df = df_clean.groupby(year_col)[amount_col].sum().reset_index()
    result_df = result_df.sort_values(year_col)

    print(f"‚úÖ –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–æ: {len(result_df)} –≥—Ä—É–ø–ø")

    # === –®–ê–ì 4: –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø ===
    print("\\nüìà –®–ê–ì 4: –°–æ–∑–¥–∞—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é...")

    plt.figure(figsize=(12, 6))
    plt.plot(result_df[year_col], result_df[amount_col],
             marker='o', linewidth=2, markersize=8)
    plt.title('–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π', fontsize=16, fontweight='bold')
    plt.xlabel(year_col, fontsize=12)
    plt.ylabel(amount_col, fontsize=12)
    plt.grid(True, alpha=0.3)

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Å—å Y —Å –∑–∞–ø—è—Ç—ã–º–∏
    ax = plt.gca()
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:,.0f}'))

    plt.tight_layout()
    print("‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å–æ–∑–¥–∞–Ω")

    # === –®–ê–ì 5: –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢ ===
    print("\\n‚úÖ –®–ê–ì 5: –§–æ—Ä–º–∏—Ä—É—é —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç...")

    # –°–æ–∑–¥–∞–µ–º MARKDOWN —Ç–∞–±–ª–∏—Ü—É (–ù–ï –∫–æ–¥-–±–ª–æ–∫!)
    display_df = result_df.copy()

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —á–∏—Å–ª–∞
    display_df[amount_col] = display_df[amount_col].apply(lambda x: f"{x:,.0f}")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Markdown —Ç–∞–±–ª–∏—Ü—É –í–†–£–ß–ù–£–Æ
    markdown_table = f"| {year_col} | {amount_col} |\\n"
    markdown_table += "|" + "-" * (len(str(year_col)) + 2) + "|" + "-" * (len(str(amount_col)) + 2) + "|\\n"

    for _, row in display_df.iterrows():
        markdown_table += f"| {int(row[year_col])} | {row[amount_col]} |\\n"

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_sum = result_df[amount_col].sum()
    avg_value = result_df[amount_col].mean()

    result = f\"\"\"
## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞

### üìà –î–∞–Ω–Ω—ã–µ –ø–æ –≥–æ–¥–∞–º

{markdown_table}

### üìå –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

| –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å | –ó–Ω–∞—á–µ–Ω–∏–µ |
|------------|----------|
| –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π | {len(df_clean)} |
| –û–±—â–∞—è —Å—É–º–º–∞ | {total_sum:,.0f} |
| –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ | {avg_value:,.0f} |

‚úÖ –ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ
\"\"\"

    print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
```

üéØ –ö–õ–Æ–ß–ï–í–´–ï –ü–†–ê–í–ò–õ–ê:

1. **–õ–û–ì–ò–†–£–ô –ö–ê–ñ–î–´–ô –®–ê–ì** —á–µ—Ä–µ–∑ print():
   - –ß—Ç–æ –¥–µ–ª–∞–µ—à—å —Å–µ–π—á–∞—Å
   - –°–∫–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
   - –ö–∞–∫–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

2. **–ò–©–ò –ö–û–õ–û–ù–ö–ò –ì–ò–ë–ö–û**:
   - –ò—Å–ø–æ–ª—å–∑—É–π —Ñ—É–Ω–∫—Ü–∏—é find_column()
   - –ò—â–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
   - –ü—Ä–æ–≤–µ—Ä—è–π —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ

3. **–ü–†–û–í–ï–†–Ø–ô –í–°–Å**:
   - –°—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
   - –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
   - –ü—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

4. **–§–û–†–ú–ê–¢–ò–†–£–ô –ß–ò–°–õ–ê**:
   - –í —Ç–∞–±–ª–∏—Ü–∞—Ö: `{value:,.0f}` –∏–ª–∏ `{value:,.2f}`
   - –ù–∞ –≥—Ä–∞—Ñ–∏–∫–∞—Ö: `plt.FuncFormatter(lambda x, p: f'{x:,.0f}')`

5. **–°–û–ó–î–ê–í–ê–ô MARKDOWN –¢–ê–ë–õ–ò–¶–´** (–ù–ï –∫–æ–¥-–±–ª–æ–∫–∏!):
   - –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞—Ç: `| –ö–æ–ª–æ–Ω–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |`
   - –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: `|---------|----------|`
   - –ì–µ–Ω–µ—Ä–∏—Ä—É–π —Ç–∞–±–ª–∏—Ü—É —Ü–∏–∫–ª–æ–º –∏–ª–∏ —á–µ—Ä–µ–∑ –ø–µ—Ç–ª—é
   - –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π ``` –≤–æ–∫—Ä—É–≥ —Ç–∞–±–ª–∏—Ü!
   - –§–æ—Ä–º–∞—Ç–∏—Ä—É–π —á–∏—Å–ª–∞ –ü–ï–†–ï–î –≤—ã–≤–æ–¥–æ–º

6. **result –í MARKDOWN**:
   - –ó–∞–≥–æ–ª–æ–≤–∫–∏ ##, ###
   - –¢–∞–±–ª–∏—Ü—ã –ù–ê–ü–†–Ø–ú–£–Æ –≤ Markdown (| col | val |)
   - –≠–º–æ–¥–∑–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏
   - **–ù–ï –ü–ï–ß–ê–¢–ê–ô result —á–µ—Ä–µ–∑ print!**
   - **–ù–ï –ò–°–ü–û–õ–¨–ó–£–ô ``` –≤–æ–∫—Ä—É–≥ —Ç–∞–±–ª–∏—Ü –¥–∞–Ω–Ω—ã—Ö!**

7. **–û–ë–†–ê–ë–û–¢–ö–ê –û–®–ò–ë–û–ö**:
   - –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã - —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º –≤ result
   - –ü–æ–∫–∞–∂–∏ –∫–∞–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
   - –î–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é

–î–æ—Å—Ç—É–ø–Ω—ã–µ DataFrame'—ã: 'df' (–æ—Å–Ω–æ–≤–Ω–æ–π){available_dataframes}

–ü–æ–º–Ω–∏: —Ç—ã –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å –ö–ê–ö –ù–ê–°–¢–û–Ø–©–ò–ô –ê–ù–ê–õ–ò–¢–ò–ö - –ø–æ—à–∞–≥–æ–≤–æ, —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏, —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏!
"""

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö –≤ –ø—Ä–æ–º–ø—Ç
        available_dataframes_text = ""
        if len(self.dataframes) > 1:
            other_files = [name for name in self.dataframes.keys()]
            if other_files:
                names_quoted = [f"'{name}'" for name in other_files]
                available_dataframes_text = f", {', '.join(names_quoted)}"

        system_prompt = system_prompt.replace("{available_dataframes}", available_dataframes_text)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        column_details = []
        for col in schema['columns']:
            dtype = schema['dtypes'][col]
            missing = schema['missing_values'].get(col, 0)

            # –ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π
            examples = []
            if len(schema['sample_data']) > 0:
                for row in schema['sample_data'][:3]:
                    val = row.get(col)
                    if pd.notna(val):
                        examples.append(str(val))

            examples_str = ", ".join(examples[:3]) if examples else "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

            col_info = f"  ‚Ä¢ '{col}' ({dtype})"
            if missing > 0:
                col_info += f" [‚ö†Ô∏è –ø—É—Å—Ç—ã—Ö: {missing}]"
            col_info += f"\n    –ü—Ä–∏–º–µ—Ä—ã: {examples_str}"
            column_details.append(col_info)

        user_message = f"""
üìä –î–ê–ù–ù–´–ï CSV –§–ê–ô–õ–ê:

–†–ê–ó–ú–ï–†: {schema['shape']['rows']} —Å—Ç—Ä–æ–∫ √ó {schema['shape']['columns']} –∫–æ–ª–æ–Ω–æ–∫

–ö–û–õ–û–ù–ö–ò:
{chr(10).join(column_details)}

–ü–†–ò–ú–ï–†–´ –ü–ï–†–í–´–• –°–¢–†–û–ö:
{json.dumps(schema['sample_data'][:3], indent=2, ensure_ascii=False)}

üéØ –ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {user_query}

‚ö° –í–ê–ñ–ù–û:
- –õ–æ–≥–∏—Ä—É–π –∫–∞–∂–¥—ã–π —à–∞–≥ —á–µ—Ä–µ–∑ print()
- –ò—â–∏ –∫–æ–ª–æ–Ω–∫–∏ –≥–∏–±–∫–æ (–ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º)
- –ü—Ä–æ–≤–µ—Ä—è–π —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
- –§–æ—Ä–º–∞—Ç–∏—Ä—É–π –í–°–ï —á–∏—Å–ª–∞
- –°–æ–∑–¥–∞–≤–∞–π –∫—Ä–∞—Å–∏–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã
"""

        if self.data_metadata.get("first_row_is_header"):
            user_message += "\n\n‚úÖ –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ CSV –±—ã–ª–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∏."

        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
        if chat_history and len(chat_history) > 0:
            history_text = "\n\n–ò—Å—Ç–æ—Ä–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:\n"
            for i, item in enumerate(chat_history[-5:], 1):
                history_text += f"\n{i}. –ó–∞–ø—Ä–æ—Å: {item.get('query', '')}\n"
                if item.get('success'):
                    history_text += f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {item.get('text_output', '')[:200]}\n"
            user_message += history_text

        if previous_error:
            user_message += f"""

–ü–†–ï–î–´–î–£–©–ê–Ø –ü–û–ü–´–¢–ö–ê –ó–ê–í–ï–†–®–ò–õ–ê–°–¨ –û–®–ò–ë–ö–û–ô:
{previous_error}

–ò—Å–ø—Ä–∞–≤—å –∫–æ–¥, —É—á–∏—Ç—ã–≤–∞—è —ç—Ç—É –æ—à–∏–±–∫—É.
"""

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ Claude/GPT
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.2,
                max_tokens=4000
            )

            code = response.choices[0].message.content.strip()

            # –£–±–∏—Ä–∞–µ–º markdown —Ä–∞–∑–º–µ—Ç–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
            if code.startswith("```python"):
                code = code[9:]
            if code.startswith("```"):
                code = code[3:]
            if code.endswith("```"):
                code = code[:-3]

            return code.strip()

        except Exception as e:
            error_msg = str(e)

            # –£–ª—É—á—à–µ–Ω–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
            if "401" in error_msg or "Unauthorized" in error_msg or "User not found" in error_msg:
                raise Exception(
                    f"–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ OpenRouter (401): API –∫–ª—é—á –Ω–µ–≤–µ—Ä–Ω—ã–π –∏–ª–∏ –∏—Å—Ç–µ–∫. "
                    f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ OPENROUTER_API_KEY –≤ .env —Ñ–∞–π–ª–µ. "
                    f"–ü–æ–ª—É—á–∏—Ç–µ –Ω–æ–≤—ã–π –∫–ª—é—á –Ω–∞ https://openrouter.ai/keys. "
                    f"–î–µ—Ç–∞–ª–∏: {error_msg}"
                )
            elif "403" in error_msg:
                raise Exception(
                    f"–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω (403): –£ API –∫–ª—é—á–∞ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –º–æ–¥–µ–ª–∏ {self.model} "
                    f"–∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤. –î–µ—Ç–∞–ª–∏: {error_msg}"
                )
            elif "429" in error_msg:
                raise Exception(
                    f"–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (429): –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API. "
                    f"–ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞. –î–µ—Ç–∞–ª–∏: {error_msg}"
                )
            else:
                raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞: {error_msg}")

    def analyze(self, user_query: str, chat_history: List[Dict] = None) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è API

        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            chat_history: –ò—Å—Ç–æ—Ä–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ API
        """
        if self.current_df is None:
            return {
                "success": False,
                "error": "CSV —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω",
                "timestamp": datetime.utcnow().isoformat()
            }

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ö–µ–º—É –¥–∞–Ω–Ω—ã—Ö
        schema = self.analyze_csv_schema(self.current_df)

        result = {
            "success": False,
            "query": user_query,
            "code_attempts": [],
            "final_code": None,
            "result_data": None,
            "text_output": None,
            "plots": [],
            "error": None,
            "attempts_count": 0,
            "timestamp": datetime.utcnow().isoformat(),
            "load_info": self.data_metadata
        }

        # –ü—Ä–æ–±—É–µ–º –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
        previous_error = None

        for attempt in range(self.max_retries):
            result["attempts_count"] = attempt + 1

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–¥
            try:
                code = self.generate_code_with_retry(
                    user_query,
                    schema,
                    chat_history,
                    previous_error
                )

                result["code_attempts"].append({
                    "attempt": attempt + 1,
                    "code": code,
                    "success": False
                })

            except Exception as e:
                result["error"] = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞: {str(e)}"
                break

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–¥
            success, exec_result, output, plot_base64_list = self.execute_python_code(
                code, self.current_df
            )

            if success:
                result["success"] = True
                result["final_code"] = code
                result["result_data"] = exec_result
                result["text_output"] = output
                result["plots"] = plot_base64_list
                result["code_attempts"][-1]["success"] = True
                break
            else:
                previous_error = output
                result["code_attempts"][-1]["error"] = output

                if attempt == self.max_retries - 1:
                    result["error"] = f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–¥ –ø–æ—Å–ª–µ {self.max_retries} –ø–æ–ø—ã—Ç–æ–∫"
                    result["error_details"] = output

        return result

    def get_schema_info(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º CSV —Ñ–∞–π–ª–µ

        Returns:
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ö–µ–º–µ –¥–∞–Ω–Ω—ã—Ö
        """
        if self.current_df is None:
            return {
                "success": False,
                "error": "CSV —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"
            }

        schema = self.analyze_csv_schema(self.current_df)
        return {
            "success": True,
            "schema": schema,
            "timestamp": datetime.utcnow().isoformat()
        }

    def cleanup(self):
        """
        –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞
        –í—ã–∑—ã–≤–∞–π—Ç–µ —ç—Ç–æ—Ç –º–µ—Ç–æ–¥ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã —Å –∞–≥–µ–Ω—Ç–æ–º
        """
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ DataFrame'—ã
        if self.current_df is not None:
            del self.current_df
            self.current_df = None

        if self.original_df is not None:
            del self.original_df
            self.original_df = None

        if self.dataframes:
            self.dataframes.clear()

        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –≤—Å–µ matplotlib —Ñ–∏–≥—É—Ä—ã
        plt.close('all')

        # –§–æ—Ä—Å–∏—Ä—É–µ–º —Å–±–æ—Ä–∫—É –º—É—Å–æ—Ä–∞
        gc.collect()
